# Issue #5: Query Processing & Orchestration Engine - Implementation Plan

## ðŸ“‹ PLAN Phase

### Problem Analysis
Issue #5 requires implementing the core orchestration engine that manages the entire query processing pipeline from user input to final response. This builds directly on the LLM integration completed in Issue #4.

### Architecture Overview
```
User Query â†’ Query Preprocessing â†’ Prompt Generation â†’ Chunk Processing â†’ Result Aggregation â†’ Response
     â†“              â†“                    â†“                  â†“                    â†“             â†“
   Intent        Dynamic            Orchestration      Progress           Context        Final
 Detection      Templates           Coordination       Tracking         Management      Output
```

### Core Components

#### 1. Query Processing Pipeline
- **QueryProcessor**: Main orchestration class
- **IntentClassifier**: Detect query type and requirements
- **QueryOptimizer**: Optimize queries for performance
- **ContextManager**: Maintain context across chunks

#### 2. Prompt Engineering System
- **PromptTemplate**: Dynamic template system
- **PromptGenerator**: Generate prompts for different query types
- **QueryTypeHandler**: Specialized handlers for different query types

#### 3. Orchestration Engine
- **ProcessingOrchestrator**: Coordinate concurrent chunk processing
- **ProgressTracker**: Real-time progress updates
- **ResultCollector**: Aggregate and validate results
- **TaskCoordinator**: Manage async task execution

#### 4. Storage & Caching
- **TemporaryStorage**: Store intermediate results
- **QueryCache**: Cache results for common queries
- **ResultValidator**: Validate and clean up results

### 3-Phase Implementation Strategy

#### Phase 1: Core Query Processing
- Query preprocessing and intent detection
- Basic prompt generation system
- Simple orchestration without progress tracking
- **Estimated**: 3-5 days

#### Phase 2: Advanced Orchestration  
- Concurrent chunk processing coordination
- Progress tracking with WebSocket updates
- Context management across chunks
- **Estimated**: 4-6 days

#### Phase 3: Optimization & Polish
- Query optimization for common patterns
- Advanced caching and result storage
- Performance monitoring and metrics
- **Estimated**: 3-4 days

### Query Types Support Matrix

| Query Type | Intent Pattern | Prompt Strategy | Context Requirements |
|------------|---------------|-----------------|---------------------|
| Quantity | "Wie viel...", "Wieviele..." | Aggregation focus | Numeric calculation |
| Component | "Welche...", "Alle..." | Entity extraction | Component identification |
| Material | "Material...", "Stoff..." | Material classification | Property analysis |
| Spatial | "Raum...", "Stock..." | Location-based | Spatial relationships |
| Cost | "Kosten...", "Preis..." | Cost calculation | Financial analysis |

### Dependencies Integration

#### From Issue #4 (LLM Integration)
- âœ… GeminiClient for API communication
- âœ… RateLimiter for API throttling
- âœ… ChunkProcessor for parallel processing
- âœ… Configuration system with LLM settings

#### New Dependencies Needed
- FastAPI for WebSocket progress updates
- Redis for temporary result storage (optional)
- asyncio task management
- Structured logging for pipeline monitoring

### File Structure

```
src/ifc_json_chunking/
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ query_processor.py      # Main orchestration
â”‚   â”œâ”€â”€ intent_classifier.py    # Query intent detection
â”‚   â”œâ”€â”€ prompt_generator.py     # Dynamic prompt system
â”‚   â”œâ”€â”€ context_manager.py      # Context preservation
â”‚   â””â”€â”€ progress_tracker.py     # Progress monitoring
â”œâ”€â”€ query/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ types.py               # Query-related types
â”‚   â”œâ”€â”€ handlers/              # Query type handlers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ quantity_handler.py
â”‚   â”‚   â”œâ”€â”€ component_handler.py
â”‚   â”‚   â”œâ”€â”€ material_handler.py
â”‚   â”‚   â”œâ”€â”€ spatial_handler.py
â”‚   â”‚   â””â”€â”€ cost_handler.py
â”‚   â””â”€â”€ templates/             # Prompt templates
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base_template.py
â”‚       â””â”€â”€ specialized_templates.py
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ temporary_storage.py   # Temporary result storage
â”‚   â”œâ”€â”€ query_cache.py         # Query result caching
â”‚   â””â”€â”€ result_validator.py    # Result validation
â””â”€â”€ monitoring/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ metrics.py             # Performance metrics
    â””â”€â”€ events.py              # Progress events
```

### Technical Specifications

#### QueryProcessor Interface
```python
class QueryProcessor:
    async def process_query(
        self,
        query: str,
        chunks: List[Chunk],
        progress_callback: Optional[Callable] = None
    ) -> QueryResult
```

#### Intent Classification
```python
class QueryIntent(Enum):
    QUANTITY = "quantity"      # Wie viel, Wieviele
    COMPONENT = "component"    # Welche, Alle
    MATERIAL = "material"      # Material, Stoff
    SPATIAL = "spatial"        # Raum, Stock
    COST = "cost"             # Kosten, Preis
    UNKNOWN = "unknown"
```

#### Progress Tracking
```python
class ProgressEvent:
    event_type: ProgressEventType
    current_step: int
    total_steps: int
    message: str
    metadata: Dict[str, Any]
```

#### Context Management
```python
class QueryContext:
    query_id: str
    intent: QueryIntent
    parameters: Dict[str, Any]
    chunk_results: List[ChunkResult]
    aggregated_context: Dict[str, Any]
```

## ðŸŽ¯ Success Criteria

### Functional Requirements
- [x] Query preprocessing pipeline with intent detection
- [x] Dynamic prompt generation for building material queries
- [x] Concurrent chunk processing orchestration
- [x] Progress tracking with real-time updates
- [x] Query context preservation across chunks
- [x] Temporary result storage with cleanup
- [x] Query optimization for common patterns
- [x] Error handling throughout the pipeline
- [x] Performance monitoring and metrics

### Technical Requirements
- Support for German building industry queries
- Sub-5-second response for <100 chunks
- >95% query intent classification accuracy
- Real-time progress updates via WebSocket
- Automatic cleanup of temporary storage
- Comprehensive error recovery
- Integration with Issue #4 LLM system

### Quality Gates
- Unit test coverage >90%
- Integration tests for all query types
- Performance benchmarks documented
- Memory usage optimized for large datasets
- Graceful degradation under load

## ðŸš€ Implementation Roadmap

### Sprint 1 (Days 1-3): Core Foundation
1. Create project structure and base classes
2. Implement QueryProcessor with basic orchestration
3. Build IntentClassifier with German query patterns
4. Create PromptGenerator with template system

### Sprint 2 (Days 4-7): Orchestration Engine
1. Implement ProcessingOrchestrator for concurrent execution
2. Add ProgressTracker with WebSocket support
3. Create ContextManager for cross-chunk context
4. Build ResultCollector for result aggregation

### Sprint 3 (Days 8-10): Storage & Optimization
1. Implement TemporaryStorage for result caching
2. Add QueryCache for performance optimization
3. Create performance monitoring and metrics
4. Build comprehensive error handling

### Sprint 4 (Days 11-12): Testing & Polish
1. Create comprehensive unit tests
2. Build integration tests for end-to-end scenarios
3. Performance testing and optimization
4. Documentation and code review

## ðŸ”— Integration Points

### With Issue #4 (LLM Integration)
- Use ChunkProcessor for parallel chunk processing
- Leverage GeminiClient for API communication
- Integrate with RateLimiter for throttling
- Extend Configuration for orchestration settings

### With Existing Codebase
- Integrate with semantic chunking strategies from Issue #3
- Use existing Chunk models and validation
- Leverage configuration system and logging
- Build on existing error handling patterns

## ðŸ“Š Performance Targets

- **Query Processing Time**: <5 seconds for typical queries
- **Concurrent Chunk Processing**: Up to 50 chunks in parallel
- **Memory Usage**: <500MB for large datasets
- **Intent Classification Accuracy**: >95% for supported patterns
- **Progress Update Frequency**: Every 100ms during processing
- **Cache Hit Rate**: >80% for repeated common queries

## Next Steps
1. Create project structure and base types
2. Implement core QueryProcessor class
3. Build IntentClassifier with German pattern matching
4. Test basic query processing pipeline